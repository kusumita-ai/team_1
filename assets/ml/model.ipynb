{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "S89AJpQYG3du"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid non-printable character U+00A0 (4031940778.py, line 8)",
          "output_type": "error",
          "traceback": [
            "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mfrom tensorflow.keras.models import Model\u001b[39m\n                                ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid non-printable character U+00A0\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers as layers\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.initializers import Constant\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflow\n",
            "  Using cached tensorflow-2.20.0-cp313-cp313-win_amd64.whl.metadata (4.6 kB)\n",
            "Collecting tensorflow-datasets\n",
            "  Downloading tensorflow_datasets-4.9.9-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in c:\\python313\\lib\\site-packages (from tensorflow) (2.3.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\python313\\lib\\site-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\python313\\lib\\site-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\python313\\lib\\site-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google_pasta>=0.1.1 in c:\\python313\\lib\\site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in c:\\python313\\lib\\site-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\python313\\lib\\site-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\kusumita\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf>=5.28.0 in c:\\python313\\lib\\site-packages (from tensorflow) (6.33.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\python313\\lib\\site-packages (from tensorflow) (2.32.5)\n",
            "Requirement already satisfied: setuptools in c:\\python313\\lib\\site-packages (from tensorflow) (80.9.0)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\kusumita\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\python313\\lib\\site-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\python313\\lib\\site-packages (from tensorflow) (4.14.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in c:\\python313\\lib\\site-packages (from tensorflow) (2.0.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\python313\\lib\\site-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.20.0 in c:\\python313\\lib\\site-packages (from tensorflow) (2.20.0)\n",
            "Requirement already satisfied: keras>=3.10.0 in c:\\python313\\lib\\site-packages (from tensorflow) (3.11.3)\n",
            "Requirement already satisfied: numpy>=1.26.0 in c:\\python313\\lib\\site-packages (from tensorflow) (2.3.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in c:\\python313\\lib\\site-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\python313\\lib\\site-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\python313\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\python313\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python313\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\python313\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.10.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\python313\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.9)\n",
            "Requirement already satisfied: pillow in c:\\python313\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (11.3.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\python313\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\python313\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
            "Collecting dm-tree (from tensorflow-datasets)\n",
            "  Downloading dm_tree-0.1.9-cp313-cp313-win_amd64.whl.metadata (2.5 kB)\n",
            "Collecting etils>=1.9.1 (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets)\n",
            "  Downloading etils-1.13.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting immutabledict (from tensorflow-datasets)\n",
            "  Downloading immutabledict-4.2.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting promise (from tensorflow-datasets)\n",
            "  Downloading promise-2.3.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: psutil in c:\\users\\kusumita\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow-datasets) (7.0.0)\n",
            "Collecting pyarrow (from tensorflow-datasets)\n",
            "  Downloading pyarrow-22.0.0-cp313-cp313-win_amd64.whl.metadata (3.3 kB)\n",
            "Collecting simple_parsing (from tensorflow-datasets)\n",
            "  Downloading simple_parsing-0.1.7-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting tensorflow-metadata (from tensorflow-datasets)\n",
            "  Downloading tensorflow_metadata-1.17.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting toml (from tensorflow-datasets)\n",
            "  Using cached toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: tqdm in c:\\python313\\lib\\site-packages (from tensorflow-datasets) (4.67.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\python313\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Collecting einops (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets)\n",
            "  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: fsspec in c:\\python313\\lib\\site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (2025.7.0)\n",
            "Collecting importlib_resources (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets)\n",
            "  Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting zipp (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets)\n",
            "  Downloading zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: rich in c:\\python313\\lib\\site-packages (from keras>=3.10.0->tensorflow) (14.2.0)\n",
            "Requirement already satisfied: namex in c:\\python313\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in c:\\python313\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\python313\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
            "Collecting attrs>=18.2.0 (from dm-tree->tensorflow-datasets)\n",
            "  Using cached attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\python313\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\kusumita\\appdata\\roaming\\python\\python313\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\python313\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n",
            "Collecting docstring-parser<1.0,>=0.15 (from simple_parsing->tensorflow-datasets)\n",
            "  Downloading docstring_parser-0.17.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting googleapis-common-protos<2,>=1.56.4 (from tensorflow-metadata->tensorflow-datasets)\n",
            "  Downloading googleapis_common_protos-1.71.0-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: colorama in c:\\users\\kusumita\\appdata\\roaming\\python\\python313\\site-packages (from tqdm->tensorflow-datasets) (0.4.6)\n",
            "Using cached tensorflow-2.20.0-cp313-cp313-win_amd64.whl (332.0 MB)\n",
            "Downloading tensorflow_datasets-4.9.9-py3-none-any.whl (5.3 MB)\n",
            "   ---------------------------------------- 0.0/5.3 MB ? eta -:--:--\n",
            "   --------- ------------------------------ 1.3/5.3 MB 9.3 MB/s eta 0:00:01\n",
            "   ----------------------------- ---------- 3.9/5.3 MB 9.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------  5.2/5.3 MB 9.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------  5.2/5.3 MB 9.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 5.3/5.3 MB 5.6 MB/s  0:00:00\n",
            "Downloading etils-1.13.0-py3-none-any.whl (170 kB)\n",
            "Downloading dm_tree-0.1.9-cp313-cp313-win_amd64.whl (102 kB)\n",
            "Using cached attrs-25.4.0-py3-none-any.whl (67 kB)\n",
            "Downloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
            "Downloading immutabledict-4.2.2-py3-none-any.whl (4.7 kB)\n",
            "Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
            "Downloading pyarrow-22.0.0-cp313-cp313-win_amd64.whl (28.0 MB)\n",
            "   ---------------------------------------- 0.0/28.0 MB ? eta -:--:--\n",
            "   --- ------------------------------------ 2.4/28.0 MB 11.2 MB/s eta 0:00:03\n",
            "   ------ --------------------------------- 4.7/28.0 MB 14.9 MB/s eta 0:00:02\n",
            "   -------- ------------------------------- 5.8/28.0 MB 9.4 MB/s eta 0:00:03\n",
            "   --------- ------------------------------ 6.6/28.0 MB 7.2 MB/s eta 0:00:03\n",
            "   ----------- ---------------------------- 8.1/28.0 MB 7.6 MB/s eta 0:00:03\n",
            "   ------------- -------------------------- 9.4/28.0 MB 7.0 MB/s eta 0:00:03\n",
            "   --------------- ------------------------ 11.0/28.0 MB 6.9 MB/s eta 0:00:03\n",
            "   ------------------- -------------------- 13.9/28.0 MB 7.8 MB/s eta 0:00:02\n",
            "   -------------------- ------------------- 14.4/28.0 MB 7.2 MB/s eta 0:00:02\n",
            "   --------------------- ------------------ 15.2/28.0 MB 6.8 MB/s eta 0:00:02\n",
            "   ------------------------- -------------- 18.1/28.0 MB 7.4 MB/s eta 0:00:02\n",
            "   --------------------------- ------------ 19.4/28.0 MB 7.4 MB/s eta 0:00:02\n",
            "   ------------------------------- -------- 21.8/28.0 MB 7.6 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 26.5/28.0 MB 8.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------  27.8/28.0 MB 8.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 28.0/28.0 MB 8.3 MB/s  0:00:03\n",
            "Downloading simple_parsing-0.1.7-py3-none-any.whl (112 kB)\n",
            "Downloading docstring_parser-0.17.0-py3-none-any.whl (36 kB)\n",
            "Downloading tensorflow_metadata-1.17.2-py3-none-any.whl (31 kB)\n",
            "Downloading googleapis_common_protos-1.71.0-py3-none-any.whl (294 kB)\n",
            "Using cached toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Downloading zipp-3.23.0-py3-none-any.whl (10 kB)\n",
            "Building wheels for collected packages: promise\n",
            "  Building wheel for promise (setup.py): started\n",
            "  Building wheel for promise (setup.py): finished with status 'done'\n",
            "  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21644 sha256=d0f1b637f7514312d0415de9a5bb14dcf4bc5818215ecfb49c6320f2b7de744c\n",
            "  Stored in directory: c:\\users\\kusumita\\appdata\\local\\pip\\cache\\wheels\\8f\\46\\1c\\1f4e5d73a20eb816ead5014e97cdeb3928cf314fc46c7bab61\n",
            "Successfully built promise\n",
            "Installing collected packages: zipp, toml, pyarrow, promise, importlib_resources, immutabledict, googleapis-common-protos, etils, einops, docstring-parser, attrs, tensorflow-metadata, simple_parsing, dm-tree, tensorflow, tensorflow-datasets\n",
            "\n",
            "   ----------------------------------------  0/16 [zipp]\n",
            "   ----------------------------------------  0/16 [zipp]\n",
            "   -- -------------------------------------  1/16 [toml]\n",
            "   -- -------------------------------------  1/16 [toml]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ----- ----------------------------------  2/16 [pyarrow]\n",
            "   ------- --------------------------------  3/16 [promise]\n",
            "   ------- --------------------------------  3/16 [promise]\n",
            "   ------- --------------------------------  3/16 [promise]\n",
            "   ---------- -----------------------------  4/16 [importlib_resources]\n",
            "   ---------- -----------------------------  4/16 [importlib_resources]\n",
            "   ---------- -----------------------------  4/16 [importlib_resources]\n",
            "   ---------- -----------------------------  4/16 [importlib_resources]\n",
            "   ---------- -----------------------------  4/16 [importlib_resources]\n",
            "   ---------- -----------------------------  4/16 [importlib_resources]\n",
            "   ------------ ---------------------------  5/16 [immutabledict]\n",
            "   ------------ ---------------------------  5/16 [immutabledict]\n",
            "   --------------- ------------------------  6/16 [googleapis-common-protos]\n",
            "   --------------- ------------------------  6/16 [googleapis-common-protos]\n",
            "   --------------- ------------------------  6/16 [googleapis-common-protos]\n",
            "   --------------- ------------------------  6/16 [googleapis-common-protos]\n",
            "   --------------- ------------------------  6/16 [googleapis-common-protos]\n",
            "   --------------- ------------------------  6/16 [googleapis-common-protos]\n",
            "   --------------- ------------------------  6/16 [googleapis-common-protos]\n",
            "   --------------- ------------------------  6/16 [googleapis-common-protos]\n",
            "   --------------- ------------------------  6/16 [googleapis-common-protos]\n",
            "   --------------- ------------------------  6/16 [googleapis-common-protos]\n",
            "   --------------- ------------------------  6/16 [googleapis-common-protos]\n",
            "   --------------- ------------------------  6/16 [googleapis-common-protos]\n",
            "   --------------- ------------------------  6/16 [googleapis-common-protos]\n",
            "   --------------- ------------------------  6/16 [googleapis-common-protos]\n",
            "   --------------- ------------------------  6/16 [googleapis-common-protos]\n",
            "   --------------- ------------------------  6/16 [googleapis-common-protos]\n",
            "   --------------- ------------------------  6/16 [googleapis-common-protos]\n",
            "   --------------- ------------------------  6/16 [googleapis-common-protos]\n",
            "   --------------- ------------------------  6/16 [googleapis-common-protos]\n",
            "   --------------- ------------------------  6/16 [googleapis-common-protos]\n",
            "   --------------- ------------------------  6/16 [googleapis-common-protos]\n",
            "   --------------- ------------------------  6/16 [googleapis-common-protos]\n",
            "   --------------- ------------------------  6/16 [googleapis-common-protos]\n",
            "   --------------- ------------------------  6/16 [googleapis-common-protos]\n",
            "   --------------- ------------------------  6/16 [googleapis-common-protos]\n",
            "   --------------- ------------------------  6/16 [googleapis-common-protos]\n",
            "   --------------- ------------------------  6/16 [googleapis-common-protos]\n",
            "   --------------- ------------------------  6/16 [googleapis-common-protos]\n",
            "   --------------- ------------------------  6/16 [googleapis-common-protos]\n",
            "   --------------- ------------------------  6/16 [googleapis-common-protos]\n",
            "   --------------- ------------------------  6/16 [googleapis-common-protos]\n",
            "   --------------- ------------------------  6/16 [googleapis-common-protos]\n",
            "   --------------- ------------------------  6/16 [googleapis-common-protos]\n",
            "   --------------- ------------------------  6/16 [googleapis-common-protos]\n",
            "   --------------- ------------------------  6/16 [googleapis-common-protos]\n",
            "   ----------------- ----------------------  7/16 [etils]\n",
            "   ----------------- ----------------------  7/16 [etils]\n",
            "   ----------------- ----------------------  7/16 [etils]\n",
            "   ----------------- ----------------------  7/16 [etils]\n",
            "   ----------------- ----------------------  7/16 [etils]\n",
            "   ----------------- ----------------------  7/16 [etils]\n",
            "   ----------------- ----------------------  7/16 [etils]\n",
            "   ----------------- ----------------------  7/16 [etils]\n",
            "   ----------------- ----------------------  7/16 [etils]\n",
            "   ----------------- ----------------------  7/16 [etils]\n",
            "   ----------------- ----------------------  7/16 [etils]\n",
            "   ----------------- ----------------------  7/16 [etils]\n",
            "   ----------------- ----------------------  7/16 [etils]\n",
            "   ----------------- ----------------------  7/16 [etils]\n",
            "   ----------------- ----------------------  7/16 [etils]\n",
            "   ----------------- ----------------------  7/16 [etils]\n",
            "   ----------------- ----------------------  7/16 [etils]\n",
            "   ----------------- ----------------------  7/16 [etils]\n",
            "   -------------------- -------------------  8/16 [einops]\n",
            "   -------------------- -------------------  8/16 [einops]\n",
            "   -------------------- -------------------  8/16 [einops]\n",
            "   -------------------- -------------------  8/16 [einops]\n",
            "   -------------------- -------------------  8/16 [einops]\n",
            "   -------------------- -------------------  8/16 [einops]\n",
            "   ---------------------- -----------------  9/16 [docstring-parser]\n",
            "   ---------------------- -----------------  9/16 [docstring-parser]\n",
            "   ---------------------- -----------------  9/16 [docstring-parser]\n",
            "   ---------------------- -----------------  9/16 [docstring-parser]\n",
            "   ---------------------- -----------------  9/16 [docstring-parser]\n",
            "   ------------------------- -------------- 10/16 [attrs]\n",
            "   ------------------------- -------------- 10/16 [attrs]\n",
            "   ------------------------- -------------- 10/16 [attrs]\n",
            "   ------------------------- -------------- 10/16 [attrs]\n",
            "   ------------------------- -------------- 10/16 [attrs]\n",
            "   ------------------------- -------------- 10/16 [attrs]\n",
            "   --------------------------- ------------ 11/16 [tensorflow-metadata]\n",
            "   --------------------------- ------------ 11/16 [tensorflow-metadata]\n",
            "   --------------------------- ------------ 11/16 [tensorflow-metadata]\n",
            "   --------------------------- ------------ 11/16 [tensorflow-metadata]\n",
            "   ------------------------------ --------- 12/16 [simple_parsing]\n",
            "   ------------------------------ --------- 12/16 [simple_parsing]\n",
            "   ------------------------------ --------- 12/16 [simple_parsing]\n",
            "   ------------------------------ --------- 12/16 [simple_parsing]\n",
            "   ------------------------------ --------- 12/16 [simple_parsing]\n",
            "   ------------------------------ --------- 12/16 [simple_parsing]\n",
            "   ------------------------------ --------- 12/16 [simple_parsing]\n",
            "   ------------------------------ --------- 12/16 [simple_parsing]\n",
            "   ------------------------------ --------- 12/16 [simple_parsing]\n",
            "   -------------------------------- ------- 13/16 [dm-tree]\n",
            "   -------------------------------- ------- 13/16 [dm-tree]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow]\n",
            "\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  DEPRECATION: Building 'promise' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'promise'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n",
            "ERROR: Could not install packages due to an OSError: [WinError 2] The system cannot find the file specified: 'c:\\\\Python313\\\\Lib\\\\site-packages\\\\tensorflow\\\\include\\\\tensorflow\\\\compiler\\\\xla\\\\hlo\\\\analysis\\\\indexing_map_serialization.h'\n",
            "\n",
            "\n",
            "[notice] A new release of pip is available: 25.2 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow tensorflow-datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Bpe2e0QhvLKX"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 128\n",
        "SAVED_MODEL_DIR = './saved_model'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "fc96HiziSiOR"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Variant folder C:\\Users\\vishn\\tensorflow_datasets\\mnist\\3.0.1 has no dataset_info.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\\Users\\vishn\\tensorflow_datasets\\mnist\\3.0.1...\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a022906183c144d0b53ae8e10330648f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Dl Completed...: 0 url [00:00, ? url/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ef06acc3cffc4985a37385e5aafc4d9f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Dl Size...: 0 MiB [00:00, ? MiB/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e66e24e235b4476384c031bdb3052277",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Extraction completed...: 0 file [00:00, ? file/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c66d015f161f4ae2aea8ed9dd10caad0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating splits...:   0%|          | 0/2 [00:00<?, ? splits/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a636d0f0ebaa4c1a93da4b31b15c3251",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train examples...: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "782854587c084979a35cbde9169ffdc6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Shuffling C:\\Users\\vishn\\tensorflow_datasets\\mnist\\incomplete.T9S1XN_3.0.1\\mnist-train.tfrecord*...:   0%|    …"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0c6314118b61464c9673b60e04b29cba",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test examples...: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ee43dfb5910347af8ac81ff25647c77b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Shuffling C:\\Users\\vishn\\tensorflow_datasets\\mnist\\incomplete.T9S1XN_3.0.1\\mnist-test.tfrecord*...:   0%|     …"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1mDataset mnist downloaded and prepared to C:\\Users\\vishn\\tensorflow_datasets\\mnist\\3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "(ds_train_data, ds_val_data), info = tfds.load(\n",
        "    name='mnist',\n",
        "    split=['train', 'test'],\n",
        "    with_info=True,\n",
        "    as_supervised=True,\n",
        ")\n",
        "\n",
        "num_classes = info.features['label'].num_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "x8N_qOpgSlLG"
      },
      "outputs": [],
      "source": [
        "def preprocess(image, label):\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = image / 255.0\n",
        "    return image, label\n",
        "\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "ds_train = (\n",
        "    ds_train_data\n",
        "    .map(preprocess, num_parallel_calls=AUTOTUNE)\n",
        "    .cache()\n",
        "    .shuffle(info.splits['train'].num_examples)\n",
        "    .batch(BATCH_SIZE)\n",
        "    .prefetch(AUTOTUNE)\n",
        ")\n",
        "\n",
        "ds_val = (\n",
        "    ds_val_data\n",
        "    .map(preprocess, AUTOTUNE)\n",
        "    .batch(BATCH_SIZE)\n",
        "    .cache()\n",
        "    .prefetch(AUTOTUNE)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "_Lq0YDUYiTMN"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\vishn\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\vishn\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\vishn\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\vishn\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\vishn\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\vishn\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "inputs = layers.Input(shape=(28, 28, 1), name='input')\n",
        "\n",
        "x = layers.Conv2D(24, kernel_size=(6, 6), strides=1)(inputs)\n",
        "x = layers.BatchNormalization(scale=False, beta_initializer=Constant(0.01))(x)\n",
        "x = layers.Activation('relu')(x)\n",
        "x = layers.Dropout(rate=0.25)(x)\n",
        "\n",
        "x = layers.Conv2D(48, kernel_size=(5, 5), strides=2)(x)\n",
        "x = layers.BatchNormalization(scale=False, beta_initializer=Constant(0.01))(x)\n",
        "x = layers.Activation('relu')(x)\n",
        "x = layers.Dropout(rate=0.25)(x)\n",
        "\n",
        "x = layers.Conv2D(64, kernel_size=(4, 4), strides=2)(x)\n",
        "x = layers.BatchNormalization(scale=False, beta_initializer=Constant(0.01))(x)\n",
        "x = layers.Activation('relu')(x)\n",
        "x = layers.Dropout(rate=0.25)(x)\n",
        "\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(200)(x)\n",
        "x = layers.BatchNormalization(scale=False, beta_initializer=Constant(0.01))(x)\n",
        "x = layers.Activation('relu')(x)\n",
        "x = layers.Dropout(rate=0.25)(x)\n",
        "\n",
        "predications = layers.Dense(num_classes, activation='softmax', name='output')(x)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=predications)\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "nBzYWAEAiwzx"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 23, 23, 24)        888       \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 23, 23, 24)        72        \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " activation (Activation)     (None, 23, 23, 24)        0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 23, 23, 24)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 10, 10, 48)        28848     \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 10, 10, 48)        144       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 10, 10, 48)        0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 10, 10, 48)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 4, 4, 64)          49216     \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 4, 4, 64)          192       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 4, 4, 64)          0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 4, 4, 64)          0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 200)               205000    \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 200)               600       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 200)               0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 200)               0         \n",
            "                                                                 \n",
            " output (Dense)              (None, 10)                2010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 286970 (1.09 MB)\n",
            "Trainable params: 286298 (1.09 MB)\n",
            "Non-trainable params: 672 (2.62 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "7L0zZdYRw3C_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.0201.\n",
            "Epoch 1/20\n",
            "WARNING:tensorflow:From C:\\Users\\vishn\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\vishn\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\vishn\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\vishn\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "469/469 [==============================] - 15s 25ms/step - loss: 0.1574 - accuracy: 0.9504 - val_loss: 0.0822 - val_accuracy: 0.9746 - lr: 0.0201\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.014430626211475785.\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 16s 33ms/step - loss: 0.0610 - accuracy: 0.9812 - val_loss: 0.0422 - val_accuracy: 0.9862 - lr: 0.0144\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.01036834238065184.\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 13s 28ms/step - loss: 0.0449 - accuracy: 0.9861 - val_loss: 0.0274 - val_accuracy: 0.9905 - lr: 0.0104\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.007457588823428847.\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 13s 28ms/step - loss: 0.0344 - accuracy: 0.9897 - val_loss: 0.0202 - val_accuracy: 0.9931 - lr: 0.0075\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.005371942762314537.\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 14s 29ms/step - loss: 0.0267 - accuracy: 0.9914 - val_loss: 0.0186 - val_accuracy: 0.9936 - lr: 0.0054\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.0038775120567512366.\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 14s 30ms/step - loss: 0.0223 - accuracy: 0.9926 - val_loss: 0.0215 - val_accuracy: 0.9930 - lr: 0.0039\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.002806705664732254.\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 14s 30ms/step - loss: 0.0199 - accuracy: 0.9935 - val_loss: 0.0169 - val_accuracy: 0.9946 - lr: 0.0028\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.002039439357288101.\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 14s 30ms/step - loss: 0.0162 - accuracy: 0.9948 - val_loss: 0.0154 - val_accuracy: 0.9946 - lr: 0.0020\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.0014896690244560313.\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 14s 30ms/step - loss: 0.0152 - accuracy: 0.9953 - val_loss: 0.0154 - val_accuracy: 0.9946 - lr: 0.0015\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.001095741367357279.\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 14s 31ms/step - loss: 0.0139 - accuracy: 0.9957 - val_loss: 0.0152 - val_accuracy: 0.9949 - lr: 0.0011\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.000813479866945048.\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 14s 31ms/step - loss: 0.0128 - accuracy: 0.9958 - val_loss: 0.0139 - val_accuracy: 0.9956 - lr: 8.1348e-04\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.0006112306641301482.\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 14s 31ms/step - loss: 0.0121 - accuracy: 0.9961 - val_loss: 0.0151 - val_accuracy: 0.9950 - lr: 6.1123e-04\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.00046631277777468366.\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 15s 31ms/step - loss: 0.0106 - accuracy: 0.9965 - val_loss: 0.0147 - val_accuracy: 0.9945 - lr: 4.6631e-04\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.00036247457473881936.\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 14s 31ms/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 0.0142 - val_accuracy: 0.9951 - lr: 3.6247e-04\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.00028807125102990415.\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 15s 31ms/step - loss: 0.0101 - accuracy: 0.9968 - val_loss: 0.0143 - val_accuracy: 0.9946 - lr: 2.8807e-04\n",
            "\n",
            "Epoch 16: LearningRateScheduler setting learning rate to 0.0002347589399817094.\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 15s 31ms/step - loss: 0.0102 - accuracy: 0.9964 - val_loss: 0.0138 - val_accuracy: 0.9954 - lr: 2.3476e-04\n",
            "\n",
            "Epoch 17: LearningRateScheduler setting learning rate to 0.00019655899987662886.\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 18s 38ms/step - loss: 0.0089 - accuracy: 0.9972 - val_loss: 0.0135 - val_accuracy: 0.9956 - lr: 1.9656e-04\n",
            "\n",
            "Epoch 18: LearningRateScheduler setting learning rate to 0.0001691875467292952.\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 15s 32ms/step - loss: 0.0089 - accuracy: 0.9973 - val_loss: 0.0140 - val_accuracy: 0.9953 - lr: 1.6919e-04\n",
            "\n",
            "Epoch 19: LearningRateScheduler setting learning rate to 0.0001495750435333272.\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 15s 32ms/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 0.0139 - val_accuracy: 0.9952 - lr: 1.4958e-04\n",
            "\n",
            "Epoch 20: LearningRateScheduler setting learning rate to 0.0001355220709146876.\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 15s 32ms/step - loss: 0.0091 - accuracy: 0.9972 - val_loss: 0.0140 - val_accuracy: 0.9951 - lr: 1.3552e-04\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x29efc99b2d0>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lr_decay = lambda epoch: 0.0001 + 0.02 * math.pow(1.0 / math.e, epoch / 3.0)\n",
        "decay_callback = LearningRateScheduler(lr_decay, verbose=1)\n",
        "\n",
        "model.fit(\n",
        "    ds_train,\n",
        "    epochs=20,\n",
        "    validation_data=ds_val,\n",
        "    callbacks=[decay_callback],\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "SwCAPICrxmRc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./saved_model\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./saved_model\\assets\n"
          ]
        }
      ],
      "source": [
        "tf.saved_model.save(model, SAVED_MODEL_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "9XVL5ULexulp"
      },
      "outputs": [],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_saved_model(SAVED_MODEL_DIR)\n",
        "# converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "# converter.target_spec.supported_types = [tf.float16]\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open('mnist.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "51PTkdoPDOTW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skip downloading\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    from google.colab import files\n",
        "    files.download('mnist.tflite')\n",
        "except:\n",
        "    print(\"Skip downloading\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "model.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
